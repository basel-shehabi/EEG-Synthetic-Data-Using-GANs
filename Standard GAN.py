import numpy as np
import os

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Silences the warning and error logs generated by TensorFlow

import matplotlib.pyplot as plt
from keras.optimizers import Adam
from keras.models import Sequential, Model
from keras.layers import Input, Dense, Flatten, LeakyReLU, Reshape, BatchNormalization


class StandardGAN:
    def __init__(self, channels=1):

        # Dataset features:
        self.channels = channels
        self.time_stamp = 1793
        self.eeg_shape = (self.time_stamp, self.channels)

        # Model specific parameters (Noise generation, Dropout for overfitting reduction, etc...):
        self.noise = 100
        self.dropout = 0.2
        self.alpha = 0.2
        self.momentum = 0.8

        # Choosing Adam optimiser for both generator and discriminator to feed in to the model:
        self.optimiser = Adam(0.0002, 0.2)  # Values from the EEG GAN paper found to be most optimal

        # Builds the Generator, Discriminator and the combined models:
        self.generator = self.make_generator()

        self.discriminator = self.make_discriminator()
        self.discriminator.compile(loss='binary_crossentropy',
                                   optimizer=self.optimiser,
                                   metrics=['accuracy'])

        self.combined = self.builder()
        self.combined.compile(loss='binary_crossentropy',
                              optimizer=self.optimiser)

        # Useful for creating a sample directory later
        self.dir = 'EEG_samples'

    def make_generator(self):
        '''
        Creates a generator model that takes in randomly generated noise, then uses
        3 Dense layers to return an image that is fed into the discriminator,
        which then distinguishes whether or not it is a real or fake one. Weights are adjusted
        accordingly such that it can eventually generate a real signal.
        :return: Model data tuple (generated noise sample, eeg img)
        '''
        model = Sequential()

        model.add(Dense(256, input_dim=self.noise))
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(Dense(512))
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(Dense(1024))
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(Dense(np.prod(self.eeg_shape), activation='tanh'))
        model.add(Reshape(self.eeg_shape))
        assert model.output_shape == (None, 1793, self.channels)

        noise = Input(shape=(self.noise,))
        img = model(noise)

        return Model(noise, img)

    def make_discriminator(self):
        '''
        Creates a discriminator model that distingushes the fed images from generator,
        and also is trained using a training loop (see below). The Discriminator is a simple
        2 Dense layer Neural Netowrk that returns either a 'True' or 'False'. Values are then adjusted accordingly
        per epoch to update weights and biases such that it produces the right output (i.e. it can
        discriminate fake from real).
        :return: Model data tuple (image from generator, validity [true or false])
        '''
        model = Sequential()

        model.add(Flatten(input_shape=self.eeg_shape))
        model.add(Dense(512))
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(Dense(256))
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(Dense(1, activation='sigmoid'))

        img = Input(shape=self.eeg_shape)
        validity = model(img)

        return Model(img, validity)

    def builder(self):
        '''
        Function that allows us to build the combined generator + discriminator model.
        In return, this lets the generator eventually fool the discriminator (Where
        the discriminator takes in the generated signal and determines whether
        it's real or fake.)

        NOTE the discriminator.trainable = False, meaning that only the generator
        is trained here, while the discriminator is not trainable for the COMBINED
        model. This step takes place before model compilation.

        :return: Model data tuple(noise signal 'z', validity [True/False])
        '''
        z = Input(shape=(self.noise,))
        generated_eeg = self.generator(z)

        discriminator = self.discriminator
        discriminator.trainable = False

        validity = discriminator(generated_eeg)

        return Model(z, validity)

    def train(self, dataset, epochs=1000, batchsize=50, sample_interval=100):
        '''
        Training function used to allow us to pass all the training data per epoch to both the generator
        and discriminator. Notice how the discriminator is still trained per batch but not for the combined
        model.
        :param dataset: input/training dataset from load_and_preprocess
        :param epochs: number of epochs (1 epoch = 1 pass of all the training data) the models loop through
        :param batchsize: number of batches.
        :param sample_interval: at what interval do we present & save the results (see below)
        :return: None
        '''

        valid = np.ones((batchsize, 1))
        fake = np.zeros((batchsize, 1))

        gen_loss = []
        disc_loss = []

        for epoch in range(epochs):

            # Discriminator Training Loop
            idx = np.random.randint(0, dataset.shape[0], batchsize)
            signal = dataset[idx]

            noise = np.random.normal(0, 1, (batchsize, self.noise))

            gen_signals = self.generator.predict(noise)

            d_loss_real = self.discriminator.train_on_batch(signal, valid)
            d_loss_fake = self.discriminator.train_on_batch(gen_signals, fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

            # Generator Training Loop
            noise = np.random.normal(0, 1, (batchsize, self.noise))

            # Combined model training where generator is trained to fool the discriminator
            g_loss = self.combined.train_on_batch(noise, valid)

            gen_loss.append(g_loss)
            disc_loss.append(d_loss[0])

            # Prints the Discriminator and Generator loss alongside accuracy
            # Per sample interval
            if epoch % sample_interval == 0:
                print("%d [Discriminator loss: %f, Accuracy: %.2f%%] [Generator loss: %f]" %
                      (epoch, d_loss[0], 100 * d_loss[1], g_loss))
                self.sample_eeg(epoch)

        plt.plot(gen_loss, 'r')
        plt.plot(disc_loss, 'b')
        plt.title('Discriminator & Generator Loss per Epoch')
        plt.xlabel('Epochs')
        plt.ylabel('Loss')
        plt.legend(['Generator Loss', 'Discriminator Loss'])
        plt.grid()
        plt.show()

    def sample_eeg(self, epoch):
        '''
        Allows us to retrieve the generated sample from the generator
        then plot it. See below comments for step by step procedure.
        :param epoch: Epoch number
        :return: None
        '''

        num_signals = 249
        noise = np.random.normal(0, 1, (num_signals, self.noise))
        gen_signal = self.generator.predict(noise)

        # Normalise
        gen_signal = 0.5 * gen_signal + 0.5

        # Plots the generated samples for the selected channels.
        # Recall the channels are chosen during the Load_and_Preprocess Script
        # Here they correspond to Fz, C3, Cz, C4 and Pz respectively.
        fig, axs = plt.subplots(5, sharex=True)
        fig.suptitle('Artificial EEG Data images per channel')
        fig.tight_layout()
        axs[0].imshow(gen_signal[:, :, 0])
        axs[0].set_title('Fz', size=10)
        axs[1].imshow(gen_signal[:, :, 1])
        axs[1].set_title('C3', size=10)
        axs[2].imshow(gen_signal[:, :, 2])
        axs[2].set_title('Cz', size=10)
        axs[3].imshow(gen_signal[:, :, 3])
        axs[3].set_title('C4', size=10)
        axs[4].imshow(gen_signal[:, :, 4])
        axs[4].set_title('Pz', size=10)

        # Save the generated samples within the current working dir
        # in a folder called 'EEG Samples', every 100 epochs.
        if not os.path.exists(self.dir):
            os.makedirs(self.dir)

        plt.savefig("%s/%d.png" % (self.dir, epoch))
        plt.close()

        return None

# Follows on from the Load_and_Preprocess Python script.
# The data file must be saved in your current working directory
x = np.load('Subject1Data.npz')
new_x = x['x']
print(new_x.shape)

# Normalise the data before input
min_val = np.min(new_x)
max_val = np.max(new_x)
normalised_data = ((new_x - min_val) / (max_val - min_val))

# Instantiate an object (telling it how many channels does the dataset have)
# Else it defaults to one.
gan = StandardGAN(channels=5)
gan.train(normalised_data, batchsize=50, epochs=2500)
